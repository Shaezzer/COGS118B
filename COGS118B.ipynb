{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inflect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4b6de4326d51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0municodedata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0minflect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'inflect'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import unicodedata\n",
    "import inflect\n",
    "import re\n",
    "from itertools import chain\n",
    "#!pip install contractions\n",
    "import contractions\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nuc24nwLI46K"
   },
   "outputs": [],
   "source": [
    "#load in the csv contatining the data\n",
    "df_original = pd.read_csv('wiki_movie_plots_deduped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create dataframes for each genre; using 1000 elements for training \n",
    "def dataframe_creator(genre):\n",
    "    genre = df_original.drop(df_original[df_original['Genre'] != genre].index, inplace = False)\n",
    "    genre.drop(['Release Year','Origin/Ethnicity','Cast', 'Wiki Page','Director','Release Year'],axis=1, \n",
    "               inplace = True)\n",
    "    genre = genre.sample(frac=1)\n",
    "    genre = genre.reset_index(drop=True)\n",
    "    genre_train = genre[0:1000]\n",
    "    genre_test = genre[1000:len(genre)]\n",
    "    return (genre_train,genre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Big Bad Wolf</td>\n",
       "      <td>horror</td>\n",
       "      <td>Two men are hunting in the jungle of Cameroon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Picture Mommy Dead</td>\n",
       "      <td>horror</td>\n",
       "      <td>Susan Shelley thinks her father, Edward, kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Jekyll and Mr. Hyde</td>\n",
       "      <td>horror</td>\n",
       "      <td>Henry Jekyll (John Barrymore) is a doctor of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Countess Dracula</td>\n",
       "      <td>horror</td>\n",
       "      <td>In 17th-century Hungary, recently widowed Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>horror</td>\n",
       "      <td>In Whitby, England in 1913, Count Dracula (Fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>The Shadow of the Cat</td>\n",
       "      <td>horror</td>\n",
       "      <td>Late at night in early 1900's England, wealthy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>Dead Man's Eyes</td>\n",
       "      <td>horror</td>\n",
       "      <td>Artist Dave Stuart is blinded by a jealous ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>The Slayer</td>\n",
       "      <td>horror</td>\n",
       "      <td>Kay is an abstract visual artist who has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>The Revenge of Frankenstein</td>\n",
       "      <td>horror</td>\n",
       "      <td>In 1860, Baron Victor Frankenstein, sentenced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>Friday the 13th: The Final Chapter</td>\n",
       "      <td>horror</td>\n",
       "      <td>The night after the events at Higgins Haven, J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title   Genre  \\\n",
       "0                          Big Bad Wolf  horror   \n",
       "1                    Picture Mommy Dead  horror   \n",
       "2               Dr. Jekyll and Mr. Hyde  horror   \n",
       "3                      Countess Dracula  horror   \n",
       "4                               Dracula  horror   \n",
       "..                                  ...     ...   \n",
       "995               The Shadow of the Cat  horror   \n",
       "996                     Dead Man's Eyes  horror   \n",
       "997                          The Slayer  horror   \n",
       "998         The Revenge of Frankenstein  horror   \n",
       "999  Friday the 13th: The Final Chapter  horror   \n",
       "\n",
       "                                                  Plot  \n",
       "0    Two men are hunting in the jungle of Cameroon ...  \n",
       "1    Susan Shelley thinks her father, Edward, kille...  \n",
       "2    Henry Jekyll (John Barrymore) is a doctor of m...  \n",
       "3    In 17th-century Hungary, recently widowed Coun...  \n",
       "4    In Whitby, England in 1913, Count Dracula (Fra...  \n",
       "..                                                 ...  \n",
       "995  Late at night in early 1900's England, wealthy...  \n",
       "996  Artist Dave Stuart is blinded by a jealous ass...  \n",
       "997  Kay is an abstract visual artist who has been ...  \n",
       "998  In 1860, Baron Victor Frankenstein, sentenced ...  \n",
       "999  The night after the events at Higgins Haven, J...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of Genres we want to run analysis on\n",
    "df_horror_train,df_horror_test = dataframe_creator('horror')\n",
    "df_comedy_train,df_comedy_test = dataframe_creator('comedy')\n",
    "\n",
    "#Creating dataframes for all genres for training\n",
    "df_train = pd.concat([df_horror_train,df_comedy_train])\n",
    "\n",
    "#creating dataframes for all genres for testing\n",
    "df_test = pd.concat([df_horror_test,df_comedy_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check word type of a word\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for text pre-processing\n",
    "def normalizeText(row):\n",
    "    \n",
    "    #create a list of punctuations we wish to delete\n",
    "    punctuations = string.punctuation\n",
    "    #create a list of stopwords in English\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    \n",
    "    #change all letters to lower case\n",
    "    row = row.lower()  \n",
    "    \n",
    "    #remove numbers\n",
    "    row = re.sub(\" \\d+\", \" \", row)\n",
    "                 \n",
    "    #remove punctutation\n",
    "    for letter in row: \n",
    "    \n",
    "        if letter in punctuations: \n",
    "            row = row.replace(letter, \"\")\n",
    "    \n",
    "    #expand the contraction I'm -> I am\n",
    "    row = contractions.fix(row)\n",
    "    # got it from (https://github.com/kootenpv/contractions)\n",
    "                \n",
    "    #remove accent char\n",
    "    row = unicodedata.normalize('NFKD', row).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "                 \n",
    "    #remove extra whitespace convert into a word  \n",
    "    row = row.strip()\n",
    "    \n",
    "    # TOKENIZATION: process of splitting text into smaller piece called tokens.\n",
    "    tokens = word_tokenize(row)\n",
    "    \n",
    "    # lemmatization step played -> play\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    row = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(row)])\n",
    "    \n",
    "    #remove stop words such as \"a\", \"the\", \"is\"\n",
    "    tokens = word_tokenize(row)\n",
    "    row = ' '.join([i for i in tokens if not i in stopWords])\n",
    "     \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the column through the normalizing function\n",
    "df_train[\"Plot\"] = df_train[\"Plot\"].apply(normalizeText) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "30Jx7UPDIMmN",
    "outputId": "18cdbc95-bf9a-4d30-e946-697c1ccdd068"
   },
   "outputs": [],
   "source": [
    "# Make list from df for \"Plot\" column\n",
    "# Param: the df to use\n",
    "def dfToList(df):\n",
    "    lst = []\n",
    "    for i, rows in df.iterrows():\n",
    "        l = [rows.Plot]\n",
    "        lst.append(l)\n",
    "    return list(chain.from_iterable(lst))\n",
    "\n",
    "# tf-idf vectorisation\n",
    "# Param: all plots from the df as a list (ie [plot1, plot2,...])\n",
    "def tfidfVec(plots):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(plots)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = tfidf.todense()\n",
    "    df_tfidf = pd.DataFrame(dense.tolist(), columns=feature_names)\n",
    "    return df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test showing how it works on first 5 elements of df_HandC\n",
    "tfidfVec(dfToList(df_train.head()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COGS118B.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
