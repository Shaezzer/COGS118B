{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "#!pip install nltk\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download()\n",
    "#!pip install sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "#nltk.download('wordnet')\n",
    "import unicodedata\n",
    "#!pip install inflect -- user\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nuc24nwLI46K"
   },
   "outputs": [],
   "source": [
    "#Loading and Cleaning Data\n",
    "\n",
    "#load in the csv contatining the data\n",
    "df_original = pd.read_csv('wiki_movie_plots_deduped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpVQi0yQI9fy"
   },
   "outputs": [],
   "source": [
    "#drop all rows in the dataframe that do not contain horror(1167) in genre catergory\n",
    "df_horror = df_original.drop(df_original[df_original['Genre'] != 'horror'].index,inplace=False)\n",
    "#drop columns we wont need\n",
    "df_horror.drop(['Release Year','Origin/Ethnicity','Cast', 'Wiki Page','Director','Release Year'],axis=1, \n",
    "               inplace = True)\n",
    "\n",
    "#reduce horror to 1000 rows\n",
    "df_horror = df_horror.sample(frac=1)\n",
    "df_horror = df_horror.reset_index(drop=True)\n",
    "df_horror_train = df_horror[0:1000]\n",
    "df_horror_test = df_horror[1000:len(df_horror)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAwh4SxaJF0s"
   },
   "outputs": [],
   "source": [
    "#drop all rows in dataframe that do not contain comedy(4379)\n",
    "df_comedy = df_original.drop(df_original[df_original['Genre'] != 'comedy'].index, inplace = False)\n",
    "df_comedy.drop(['Release Year','Origin/Ethnicity','Cast', 'Wiki Page','Director','Release Year'],axis=1, \n",
    "               inplace = True)\n",
    "#reduce horror to 1000 rows\n",
    "df_comedy = df_comedy.sample(frac=1)\n",
    "df_comedy = df_comedy.reset_index(drop=True)\n",
    "df_comedy_train = df_comedy[0:1000]\n",
    "df_comedy_test = df_comedy[1000:len(df_comedy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4-RZfoyJUvr"
   },
   "outputs": [],
   "source": [
    "#merge the comedy and horror dataframes into one\n",
    "df_HandC = pd.concat([df_horror_test,df_comedy_test])\n",
    "\n",
    "#Pre punctuation parsing test\n",
    "#df_HandC.iloc[1002]['Plot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get rid of punctuation\n",
    "def normalizeText(row):\n",
    "    #create a list of punctuations we wish to delete\n",
    "    punctuations = string.punctuation\n",
    "    \n",
    "    #create a list of stopwords in English\n",
    "    stopWords = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "    #change all letters to lower case\n",
    "    row=row.lower()  \n",
    "    \n",
    "    #loop through each word and get rid of punctuation and \\r\\n that came with data\n",
    "    # also do the lemmatizer step where played is converted to \n",
    "    # also remove the stop words such as a/the/of/...\n",
    "    for x in row: \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatizer.lemmatize(x)\n",
    "        \n",
    "        if x in punctuations: \n",
    "            row = row.replace(x, \"\")\n",
    "        if x in stopWords:\n",
    "            row = row.replace(x,\"\")\n",
    "        row = row.replace('\\r\\n', '')\n",
    "    \n",
    "    return row\n",
    "#run the column through the normalizing function\n",
    "df_HandC[\"Plot\"] = df_HandC[\"Plot\"].apply(normalizeText) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accented characters.\n",
    "# Param: entire string will be converted, punctuation accepted\n",
    "def removeAccents(string):\n",
    "    return unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numbers with word representation.\n",
    "# NOTE: run before removing punctuation, result will have punctuation\n",
    "# Param: single num, no punctuation or spaces within the string\n",
    "def numToWord(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return inflect.engine().number_to_words(num)\n",
    "    except ValueError:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLdPVNgzN1Bx"
   },
   "outputs": [],
   "source": [
    "#Post Punctuation Parsing test\n",
    "#df_HandC.iloc[1002]['Plot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "30Jx7UPDIMmN",
    "outputId": "18cdbc95-bf9a-4d30-e946-697c1ccdd068"
   },
   "outputs": [],
   "source": [
    "##Prabesh being stupid. might be helpful?\n",
    "\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#tfidf = vectorizer.fit_transform(df_HandC['Plot'])\n",
    "#print similarity matrix\n",
    "#print((tfidf*tfidf.T).A)\n",
    "\n",
    "# Make list from df for \"Plot\" column\n",
    "# Param: the df to use\n",
    "from itertools import chain\n",
    "def dfToList(df):\n",
    "    lst = []\n",
    "    for i, rows in df.iterrows():\n",
    "        l = [rows.Plot]\n",
    "        lst.append(l)\n",
    "    return list(chain.from_iterable(lst))\n",
    "\n",
    "# tf-idf vectorisation\n",
    "# Param: all plots from the df as a list (ie [plot1, plot2,...])\n",
    "def tfidfVec(plots):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(plots)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = tfidf.todense()\n",
    "    df_tfidf = pd.DataFrame(dense.tolist(), columns=feature_names)\n",
    "    return df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>10h</th>\n",
       "      <th>11</th>\n",
       "      <th>1980</th>\n",
       "      <th>bbe</th>\n",
       "      <th>bck</th>\n",
       "      <th>be</th>\n",
       "      <th>bece</th>\n",
       "      <th>becue</th>\n",
       "      <th>been</th>\n",
       "      <th>...</th>\n",
       "      <th>wr</th>\n",
       "      <th>wren</th>\n",
       "      <th>wrk</th>\n",
       "      <th>wrlel</th>\n",
       "      <th>wrng</th>\n",
       "      <th>wun</th>\n",
       "      <th>zbe</th>\n",
       "      <th>zben</th>\n",
       "      <th>zucc</th>\n",
       "      <th>zurk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026656</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214753</td>\n",
       "      <td>0.016519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028884</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.046608</td>\n",
       "      <td>0.048361</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>0.023304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041179</td>\n",
       "      <td>0.041179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10       10h        11      1980       bbe       bck        be  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.013328  0.022127   \n",
       "2  0.028884  0.014442  0.014442  0.014442  0.014442  0.046608  0.048361   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.031888   \n",
       "\n",
       "       bece     becue      been  ...        wr      wren       wrk     wrlel  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.026656  0.013328  ...  0.013328  0.000000  0.000000  0.016519   \n",
       "2  0.011652  0.011652  0.023304  ...  0.000000  0.014442  0.014442  0.000000   \n",
       "3  0.033223  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  ...  0.038415  0.000000  0.000000  0.000000   \n",
       "\n",
       "       wrng       wun       zbe      zben      zucc      zurk  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.214753  0.016519  0.000000  0.000000  \n",
       "2  0.014442  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.041179  0.000000  0.000000  0.041179  0.041179  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 618 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test showing how it works on first 5 elements of df_HandC\n",
    "tfidfVec(dfToList(df_HandC.head()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COGS118B.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
